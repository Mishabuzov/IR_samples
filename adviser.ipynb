{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ENJNmwv1ope"
   },
   "source": [
    "# Sugges_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2YrBebD1opi"
   },
   "source": [
    "One of the strategies to improve user experience is to provide user with hints, or, otherwise, to autocomplete his queries. Let's consider suggest. This notebook contains implementation of [Trie](https://en.wikipedia.org/wiki/Trie) datastructure (prefix tree), that uses in order to complete user query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXUpWGm_1opk"
   },
   "source": [
    "## Install Trie DS support\n",
    "\n",
    "https://github.com/google/pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kv6vRzN21opm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygtrie in /home/misha/environments/main/lib/python3.7/site-packages (2.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygtrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlEiOV4w1opu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharTrie(this is 1: A, this is 2: B, that is 3: C)\n",
      "Node = False; Subtree = True\n",
      "this is 1 ~ A\n",
      "this is 2 ~ B\n"
     ]
    }
   ],
   "source": [
    "import pygtrie\n",
    "t = pygtrie.CharTrie()\n",
    "t[\"this is 1\"] = \"A\"\n",
    "t[\"this is 2\"] = \"B\"\n",
    "t[\"that is 3\"] = \"C\"\n",
    "\n",
    "print(t)\n",
    "\n",
    "n = t.has_node('this') == pygtrie.Trie.HAS_VALUE\n",
    "s = t.has_node('this') == pygtrie.Trie.HAS_SUBTRIE\n",
    "\n",
    "print(f\"Node = {n}; Subtree = {s}\")\n",
    "\n",
    "for key, val in t.iteritems(\"this\"):\n",
    "    print(key, '~', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DsiIlgu1op1"
   },
   "source": [
    "## 1. Build a trie upon a dataset ##\n",
    "\n",
    "### 1.1 Read dataset\n",
    "\n",
    "Download the [dataset](https://drive.google.com/drive/folders/1rOE5eed37Jy2ANQItZVwDIFgPmkCoFu6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNZTgNu01op3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS size: 3558411\n",
      "DS head:\n",
      "   AnonID                        Query            QueryTime      ItemRank  \\\n",
      "0     142               rentdirect.com  2006-03-01 07:17:12  9.223372e+18   \n",
      "1     142  www.prescriptionfortime.com  2006-03-12 12:31:06  9.223372e+18   \n",
      "2     142                   staple.com  2006-03-17 21:19:29  9.223372e+18   \n",
      "3     142                   staple.com  2006-03-17 21:19:45  9.223372e+18   \n",
      "4     142    www.newyorklawyersite.com  2006-03-18 08:02:58  9.223372e+18   \n",
      "\n",
      "  ClickURL  \n",
      "0           \n",
      "1           \n",
      "2           \n",
      "3           \n",
      "4           \n",
      "DS tail:\n",
      "           AnonID                      Query            QueryTime  \\\n",
      "3558406  24968114                          -  2006-05-31 01:04:20   \n",
      "3558407  24969251  sp.trafficmarketplace.com  2006-05-31 15:51:23   \n",
      "3558408  24969374            orioles tickets  2006-05-31 12:24:51   \n",
      "3558409  24969374            orioles tickets  2006-05-31 12:31:57   \n",
      "3558410  24969374          baltimore marinas  2006-05-31 12:43:40   \n",
      "\n",
      "             ItemRank                   ClickURL  \n",
      "3558406  9.223372e+18                             \n",
      "3558407  9.223372e+18                             \n",
      "3558408  9.223372e+18                             \n",
      "3558409  2.000000e+00  http://www.greatseats.com  \n",
      "3558410  9.223372e+18                             \n"
     ]
    }
   ],
   "source": [
    "#TODO: Read the dataset\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# value of the worst rank, which means that user have not clicked any url by the query\n",
    "NON_CLICKED_FLAG = sys.maxsize\n",
    "\n",
    "aol_data = pd.read_csv(\"user-ct-test-collection-01.txt\", sep=\"\\t\")\n",
    "\n",
    "# replace NaN with sys.maxsize for ItemRank and with '' for ClickURL columns \n",
    "# just for more convenient processing.\n",
    "aol_data['ClickURL'] = aol_data['ClickURL'].replace(pd.np.nan, '', regex=True)\n",
    "aol_data['ItemRank'] = aol_data['ItemRank'].replace(pd.np.nan, NON_CLICKED_FLAG, regex=True)\n",
    "\n",
    "print(\"DS size:\", aol_data.shape[0])\n",
    "print(\"DS head:\")\n",
    "print(aol_data.head())\n",
    "print(\"DS tail:\")\n",
    "print(aol_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Build Trie\n",
    "\n",
    "Suggest function have to be non-sensitive to stop words because user can confuse/omit prepositions.\n",
    "\n",
    "Trie is based on the dataset, query statistics such as query frequency, urls and ranks in nodes are stored. Some queries may not have associated urls, others may have multiple ranked urls (in this case only the most relevant one is stored for reasons of memory saving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/misha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"Class for preprocessing of the extracted queries.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return nltk.word_tokenize(text)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize lowercased text, and remove stop-words. \n",
    "        Returns queries without stop-words.\n",
    "        \"\"\"\n",
    "        text = str(text).lower().strip()\n",
    "        tokenized_text = self.tokenize(text)\n",
    "        return \" \".join([word for word in tokenized_text if word not in self.stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           AnonID                      Query            QueryTime  \\\n",
      "3558406  24968114                          -  2006-05-31 01:04:20   \n",
      "3558407  24969251  sp.trafficmarketplace.com  2006-05-31 15:51:23   \n",
      "3558408  24969374            orioles tickets  2006-05-31 12:24:51   \n",
      "3558409  24969374            orioles tickets  2006-05-31 12:31:57   \n",
      "3558410  24969374          baltimore marinas  2006-05-31 12:43:40   \n",
      "\n",
      "             ItemRank                   ClickURL            processed_query  \n",
      "3558406  9.223372e+18                                                     -  \n",
      "3558407  9.223372e+18                             sp.trafficmarketplace.com  \n",
      "3558408  9.223372e+18                                       orioles tickets  \n",
      "3558409  2.000000e+00  http://www.greatseats.com            orioles tickets  \n",
      "3558410  9.223372e+18                                     baltimore marinas  \n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "\n",
    "# create a column in the dataframe, which contains query without stop-words.\n",
    "aol_data['processed_query'] = [preprocessor.preprocess(query) for query in aol_data['Query']]\n",
    "\n",
    "print(aol_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_COUNT_KEY = 'count'\n",
    "RANK_KEY = 'rank'\n",
    "URL_KEY = 'url'\n",
    "\n",
    "\n",
    "def build_aol_trie():\n",
    "    \"\"\" build trie based on data \"\"\" \n",
    "    \n",
    "    def find_query_in_aol_trie(similar_queries, query, query_rank, query_url):\n",
    "        if query in similar_queries:\n",
    "            query_params = similar_queries[query]\n",
    "            query_params[QUERY_COUNT_KEY] += 1  # increase occurence of query met\n",
    "            \n",
    "            # keep just url with best rank for saving memory:\n",
    "            if query_rank < query_params[RANK_KEY]:\n",
    "                query_params[RANK_KEY] = query_rank\n",
    "                query_params[URL_KEY] = query_url\n",
    "        else:\n",
    "            similar_queries[query] = {QUERY_COUNT_KEY: 1, \n",
    "                                      RANK_KEY: query_rank, \n",
    "                                      URL_KEY: query_url}\n",
    "    \n",
    "    aol_trie = pygtrie.CharTrie()\n",
    "    for processed_query, query, rank, url in zip(aol_data['processed_query'],\n",
    "                                                 aol_data['Query'],\n",
    "                                                 aol_data['ItemRank'],\n",
    "                                                 aol_data['ClickURL']):\n",
    "        if processed_query not in aol_trie:\n",
    "            aol_trie[processed_query] = dict()\n",
    "\n",
    "        find_query_in_aol_trie(aol_trie[processed_query], query, rank, url)\n",
    "    \n",
    "    return aol_trie\n",
    "\n",
    "aol_trie = build_aol_trie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample question surveys ~ {'sample question surveys': {'count': 5, 'rank': 1.0, 'url': 'http://www.lg-employers.gov.uk'}}\n",
      "sample questions immigration interview ~ {'sample questions for immigration interview': {'count': 1, 'rank': 9.223372036854776e+18, 'url': ''}}\n",
      "sample questions interview ~ {'sample questions for interview': {'count': 1, 'rank': 1.0, 'url': 'http://www.quintcareers.com'}}\n",
      "sample questions family interview ~ {'sample questions for family interview': {'count': 3, 'rank': 2.0, 'url': 'http://www.grandparents-day.com'}}\n",
      "sample questions sociology race ethnicity ~ {'sample questions sociology race and ethnicity': {'count': 1, 'rank': 9.223372036854776e+18, 'url': ''}}\n",
      "sample questions biology ~ {'sample questions biology': {'count': 2, 'rank': 3.0, 'url': 'http://www.utexas.edu'}}\n",
      "sample questions us citizenship test ~ {'sample questions for us citizenship test': {'count': 1, 'rank': 1.0, 'url': 'http://uscis.gov'}}\n",
      "sample questionarie teaching evaluation ~ {'sample questionarie teaching evaluation': {'count': 1, 'rank': 9.223372036854776e+18, 'url': ''}}\n",
      "sample questionnaire teaching evaluation ~ {'sample questionnaire teaching evaluation': {'count': 5, 'rank': 1.0, 'url': 'http://www.surveyconsole.com'}}\n",
      "sample questionnaire clinical research coordinators certification ~ {'sample questionnaire for clinical research coordinators certification': {'count': 1, 'rank': 9.0, 'url': 'http://www.pharmatech.com'}}\n"
     ]
    }
   ],
   "source": [
    "# test trie\n",
    "for key, val in aol_trie.iteritems(\"sample q\"):\n",
    "    print(key, '~', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30u0nb8f1osE"
   },
   "source": [
    "## 2. Implementation of a suggest function which is non-sensitive to stop words ##\n",
    "\n",
    "Suggest options for user query based on Trie.\n",
    "Output results sorted by frequency, query count for each suggestion is printed. If there is an url available, it is also printed. If multiple url-s are available, the one with the highest rank (the less the better) is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZzx2Vp31osB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: trie\n",
      "Results:\n",
      "Count 5 : tried and true tattoo http://www.triedntruetattoo.com\n",
      "Count 3 : triest \n",
      "Count 3 : triethanalomine http://avalon.unomaha.edu\n",
      "Count 2 : tried and failed \n",
      "Count 2 : when you tried and failed \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def complete_user_query(query, trie, top_k=5):\n",
    "    \"\"\" suggest top_k options for a user query.\n",
    "    Sort results by frequency, suggest first ranked urls if available\"\"\" \n",
    "    \n",
    "    def find_complete_queries(preprocessed_query, completed_queries):\n",
    "        \"\"\"make search in trie by given preprocessed_query, and return sorted (by frequency) results.\"\"\"\n",
    "        for full_processed_queries, full_init_queries_dict in trie.iteritems(preprocessed_query):\n",
    "            for full_init_query, init_query_param in full_init_queries_dict.items():\n",
    "                completed_queries.append((init_query_param[QUERY_COUNT_KEY], full_init_query, init_query_param[URL_KEY]))\n",
    "\n",
    "        return sorted(completed_queries, key=lambda item: item[0], reverse=True)[:top_k]\n",
    "    \n",
    "    \n",
    "    if len(query) == 0:  # just check on dull case:\n",
    "        print(\"Your query is empty\")\n",
    "        return\n",
    "        \n",
    "    completed_queries = []\n",
    "    preprocessed_query = preprocessor.preprocess(query)\n",
    "    \n",
    "    if len(preprocessed_query) == 0:  # can be true if query consist only of stopwords.\n",
    "        preprocessed_query = query  # try to find at least smth.\n",
    "\n",
    "    if trie.has_subtrie(preprocessed_query) or trie.has_key(preprocessed_query):\n",
    "        completed_queries = find_complete_queries(preprocessed_query, completed_queries)\n",
    "    \n",
    "    if len(completed_queries) == 0:\n",
    "        print(\"Sorry, nothing to suggest!\")\n",
    "    else:\n",
    "        [print(f\"Count {complete_query[0]} : {complete_query[1]} {complete_query[2]}\") for complete_query in completed_queries]\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "inp = \"trie\"\n",
    "print(\"Query:\", inp)\n",
    "print(\"Results:\")\n",
    "complete_user_query(inp, aol_trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6Uivwxk1osF"
   },
   "source": [
    "## 3. Measure suggest speed ##\n",
    "\n",
    "Check how fast search is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: inf\n",
      "Results:\n",
      "Count 94 : information clearing house http://www.informationclearinghouse.info\n",
      "Count 72 : information on training puppy http://www.101-dog-training-tips.com\n",
      "Count 59 : inflatable slides \n",
      "Count 46 : infopass http://infopass.uscis.gov\n",
      "Count 40 : infolanka http://www.infolanka.com\n",
      "\n",
      "\n",
      "Query: the best \n",
      "Results:\n",
      "Count 685 : best buy http://www.bestbuy.com\n",
      "Count 257 : bestcounter.biz \n",
      "Count 224 : bestbuy http://www.bestbuy.com\n",
      "Count 158 : bestbuy.com http://www.bestbuy.com\n",
      "Count 99 : best western http://www.bestwestern.com\n",
      "\n",
      "\n",
      "Query: information retrieval\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query: sherlock hol\n",
      "Results:\n",
      "Count 4 : sherlock holmes http://www.sherlockian.net\n",
      "Count 2 : sherlock holmes society http://www.realtime.net\n",
      "Count 2 : sherlock holmes chronological order http://www.geocities.com\n",
      "Count 1 : sherlock holmes address \n",
      "Count 1 : sherlock holmes audiotapes \n",
      "\n",
      "\n",
      "Query: carnegie mell\n",
      "Results:\n",
      "Count 6 : carnegie mellon http://www.cmu.edu\n",
      "Count 1 : carnegie mellon university http://www.cmu.edu\n",
      "\n",
      "\n",
      "Query: babies r\n",
      "Results:\n",
      "Count 308 : babies r us http://www.toysrus.com\n",
      "Count 15 : babies r us.com http://www.toysrus.com\n",
      "Count 6 : babies r' us http://www.babiesrus.com\n",
      "Count 5 : babies r us birmingham al registry http://birmingham.babyzone.com\n",
      "Count 4 : babies r us regestry \n",
      "\n",
      "\n",
      "Query: new york\n",
      "Results:\n",
      "Count 425 : new york times http://www.nytimes.com\n",
      "Count 192 : new york lottery http://www.nylottery.org\n",
      "Count 122 : new york alarm installer jobs http://websearch.nytimes.com\n",
      "Count 118 : new york university http://www.nyu.edu\n",
      "Count 96 : new york city http://www.nyc.gov\n",
      "\n",
      "\n",
      "Query: googol\n",
      "Results:\n",
      "Count 9 : googole http://www.googole.com\n",
      "Count 8 : googol http://en.wikipedia.org\n",
      "Count 6 : googol . com. http://mathworld.wolfram.com\n",
      "Count 1 : googolle \n",
      "Count 1 : googol.cokm \n",
      "\n",
      "\n",
      "Query: inter\n",
      "Results:\n",
      "Count 4207 : internet http://www.microsoft.com\n",
      "Count 216 : internal revenue service http://www.irs.gov\n",
      "Count 189 : internet explorer http://www.microsoft.com\n",
      "Count 66 : international male.com \n",
      "Count 42 : international bar association http://www.ibanet.org\n",
      "\n",
      "\n",
      "Query: USA sta\n",
      "Results:\n",
      "Count 1 : usa state map \n",
      "\n",
      "\n",
      "Query: Barbara \n",
      "Results:\n",
      "Count 23 : barbara ann priddy teacher oklahoma city oklahoma \n",
      "Count 21 : barbara eden http://www.imdb.com\n",
      "Count 14 : barbara a priddy oklahoma city oklahoma http://www.oklahomahistory.net\n",
      "Count 14 : barbara franzoso http://www.seacoastonline.com\n",
      "Count 13 : barbara ann priddy psychiatric history \n",
      "\n",
      "\n",
      "Queries are handled in 17.6 ms on average\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "inp_queries = [\"inf\", \"the best \", \"information retrieval\", \"sherlock hol\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"inter\", \"USA sta\", \"Barbara \"]\n",
    "\n",
    "#TODO: measure avg execution time per query\n",
    "start = time.time()\n",
    "for query in inp_queries:\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Results:\")\n",
    "    complete_user_query(query, aol_trie)\n",
    "\n",
    "avg_time = round((time.time() - start) * 1000 / len(inp_queries), 2)\n",
    "\n",
    "print(f\"Queries are handled in {avg_time} ms on average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gH_RNJRj1osG"
   },
   "source": [
    "## 4. Adding spellchecking to adviser ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build Soundex spellchecker, based on the query data provided in the current dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 568101 terms\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_vocabulary():\n",
    "    vocabulary = Counter()\n",
    "    for query_data in aol_data['processed_query']:\n",
    "        for term in preprocessor.tokenize(query_data):\n",
    "            if (len(term)) > 1:\n",
    "                vocabulary[term] += 1\n",
    "    print(\"Vocabulary contains\", len(vocabulary), \"terms\")\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = create_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aML22Syo1osH"
   },
   "outputs": [],
   "source": [
    "def edit_dist(s1, s2) -> int:\n",
    "    \"\"\" compute the Damerau-Levenshtein distance between two given strings (s1 and s2)\n",
    "     Transposition is considered as operation. The snippet is taken from the corresponding Wikipedia page. \"\"\" \n",
    "    d = {}\n",
    "    lenstr1 = len(s1)\n",
    "    lenstr2 = len(s2)\n",
    "    for i in range(-1,lenstr1+1):\n",
    "        d[(i,-1)] = i+1\n",
    "    for j in range(-1,lenstr2+1):\n",
    "        d[(-1,j)] = j+1\n",
    " \n",
    "    for i in range(lenstr1):\n",
    "        for j in range(lenstr2):\n",
    "            if s1[i] == s2[j]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            d[(i,j)] = min(\n",
    "                           d[(i-1,j)] + 1, # deletion\n",
    "                           d[(i,j-1)] + 1, # insertion\n",
    "                           d[(i-1,j-1)] + cost, # substitution\n",
    "                          )\n",
    "            if i and j and s1[i]==s2[j-1] and s1[i-1] == s2[j]:\n",
    "                d[(i,j)] = min (d[(i,j)], d[i-2,j-2] + cost) # transposition\n",
    " \n",
    "    return d[lenstr1-1,lenstr2-1]\n",
    "\n",
    "def produce_soundex_code(word):\n",
    "    \"\"\" Soundex algorithm implementation\n",
    "     input word, which should be already lowercased\n",
    "     return Soundex 4-character code, like 'k450' \"\"\"\n",
    "\n",
    "    def replace_letters(editable_word: str, \n",
    "                        exchange_letters: list, \n",
    "                        replace_symbol: str):\n",
    "        \"\"\"replace all the exchange_letters in editable_word to \n",
    "        replace_symbol.\"\"\"\n",
    "        for change_letter in exchange_letters:\n",
    "            editable_word = editable_word.replace(change_letter, replace_symbol)\n",
    "        return editable_word\n",
    "        \n",
    "    soundex_code = word[0]\n",
    "    \n",
    "    if len(word) > 1:\n",
    "        editable_word = word[1:]\n",
    "        \n",
    "        # since \"word\" can represent some url, it can contains spec. symbols and numbers,\n",
    "        # let replace it with some additional code.\n",
    "        spec_symbols = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '-', '@', '\\'', '\"', '.', ',']\n",
    "        editable_word = replace_letters(editable_word, spec_symbols, '7')\n",
    "        \n",
    "        zero_letters = ['a', 'e', 'i', 'o', 'u', 'h', 'w', 'y']\n",
    "        editable_word = replace_letters(editable_word, zero_letters, '0')\n",
    "\n",
    "        one_letters = ['b', 'f', 'p', 'v']\n",
    "        editable_word = replace_letters(editable_word, one_letters, '1')\n",
    "\n",
    "        two_letters = ['c', 'g', 'j', 'k', 'q', 's', 'x', 'z']\n",
    "        editable_word = replace_letters(editable_word, two_letters, '2')\n",
    "\n",
    "        editable_word = replace_letters(editable_word, ['d', 't'], '3')\n",
    "        editable_word = replace_letters(editable_word, ['l'], '4')\n",
    "        editable_word = replace_letters(editable_word, ['m', 'n'], '5')\n",
    "        editable_word = replace_letters(editable_word, ['r'], '6')\n",
    "\n",
    "        soundex_code += editable_word[0]\n",
    "        prev_char_ind = 0\n",
    "        # Repeatedly save one digit out of each pair of consecutive identical digits.\n",
    "        for char_ind in range(1, len(editable_word)):\n",
    "            if editable_word[prev_char_ind] != editable_word[char_ind]:\n",
    "                soundex_code += editable_word[char_ind]\n",
    "                prev_char_ind = char_ind\n",
    "    \n",
    "    # Pad the resulting string with trailing zeros and return the first four positions\n",
    "    return (soundex_code.replace('0', '') + '0' * 3)[:4]\n",
    "\n",
    "\n",
    "def build_soundex_index(dictionary):\n",
    "    # dictionary is a vocabulary of original words\n",
    "    # output format: 'code1': ['word1_with_code1', 'word2_with_code1', ...]    \n",
    "\n",
    "    soundex_index = {}\n",
    "    for word in dictionary:\n",
    "        code = produce_soundex_code(word)\n",
    "        if code not in soundex_index:\n",
    "            soundex_index[code] = [word]\n",
    "        else:\n",
    "            soundex_index[code].append(word)\n",
    "    return soundex_index\n",
    "\n",
    "\n",
    "soundex_index = build_soundex_index(vocabulary)\n",
    "\n",
    "\n",
    "def fix_typo_soundex(word):\n",
    "    # return words from vocabulary that match with result by soundex fingerprint\n",
    "    # ordered results by editorial distance\n",
    "    word_sound_code = produce_soundex_code(word)\n",
    "    if word_sound_code not in soundex_index:\n",
    "        return [word]\n",
    "    \n",
    "    words_edit_distances = {}  # match similar sound word with its edit. dist. till orig. word\n",
    "    for similar_sound_word in soundex_index[word_sound_code]:\n",
    "        words_edit_distances[similar_sound_word] = edit_dist(word, similar_sound_word)\n",
    "    \n",
    "    # sort obtained similar words by editorial distance (dict value), and return best match:\n",
    "    return [k for k, _ in sorted(words_edit_distances.items(), key=lambda item: item[1])][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_with_spellchecker(query):\n",
    "    preprocessed_query = query.lower()\n",
    "    fixed_terms = []\n",
    "    \n",
    "    for query_term in preprocessor.tokenize(preprocessed_query):\n",
    "        if query_term in preprocessor.stop_words:\n",
    "            fixed_terms.append(query_term)  # let's left stop-words as it are.\n",
    "            continue\n",
    "        \n",
    "        fixed_terms.append(fix_typo_soundex(query_term))  # correct query term\n",
    "    return \" \".join(fixed_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also test spellchecker on some queries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: infa\n",
      "Results:\n",
      "Count 28 : infatuated \n",
      "Count 9 : infantry flash games war http://www.popmatters.com\n",
      "Count 8 : infant of prague novena http://www.thesacredheart.com\n",
      "Count 8 : infant dumbo costume http://www.brandsonsale.com\n",
      "Count 7 : infant easter outfit http://www.bunnycreek.com\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: info\n",
      "Results with spellchecker:\n",
      "Count 94 : information clearing house http://www.informationclearinghouse.info\n",
      "Count 72 : information on training puppy http://www.101-dog-training-tips.com\n",
      "Count 46 : infopass http://infopass.uscis.gov\n",
      "Count 40 : infolanka http://www.infolanka.com\n",
      "Count 29 : infospace http://www.infospace.com\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: cliar hestory\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: clear history\n",
      "Results with spellchecker:\n",
      "Count 109 : clear history http://www.hopeforhealing.org\n",
      "Count 11 : clear my history \n",
      "Count 7 : clear history trail http://www.boutell.com\n",
      "Count 4 : how to clear history \n",
      "Count 4 : clear my history list http://blogs.msdn.com\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: the best \n",
      "Results:\n",
      "Count 685 : best buy http://www.bestbuy.com\n",
      "Count 257 : bestcounter.biz \n",
      "Count 224 : bestbuy http://www.bestbuy.com\n",
      "Count 158 : bestbuy.com http://www.bestbuy.com\n",
      "Count 99 : best western http://www.bestwestern.com\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: the best\n",
      "Results with spellchecker:\n",
      "Count 685 : best buy http://www.bestbuy.com\n",
      "Count 257 : bestcounter.biz \n",
      "Count 224 : bestbuy http://www.bestbuy.com\n",
      "Count 158 : bestbuy.com http://www.bestbuy.com\n",
      "Count 99 : best western http://www.bestwestern.com\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: infarmation retrieval\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: information retrieval\n",
      "Results with spellchecker:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: sherlack holm\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: sherlock holm\n",
      "Results with spellchecker:\n",
      "Count 4 : sherlock holmes http://www.sherlockian.net\n",
      "Count 2 : sherlock holmes society http://www.realtime.net\n",
      "Count 2 : sherlock holmes chronological order http://www.geocities.com\n",
      "Count 1 : sherlock holmes address \n",
      "Count 1 : sherlock holmes audiotapes \n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: carnegie mell\n",
      "Results:\n",
      "Count 6 : carnegie mellon http://www.cmu.edu\n",
      "Count 1 : carnegie mellon university http://www.cmu.edu\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: carnegie mell\n",
      "Results with spellchecker:\n",
      "Count 6 : carnegie mellon http://www.cmu.edu\n",
      "Count 1 : carnegie mellon university http://www.cmu.edu\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: babies r\n",
      "Results:\n",
      "Count 308 : babies r us http://www.toysrus.com\n",
      "Count 15 : babies r us.com http://www.toysrus.com\n",
      "Count 6 : babies r' us http://www.babiesrus.com\n",
      "Count 5 : babies r us birmingham al registry http://birmingham.babyzone.com\n",
      "Count 4 : babies r us regestry \n",
      "\n",
      "\n",
      "Query fixed with spellchecker: babies ri\n",
      "Results with spellchecker:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: new york\n",
      "Results:\n",
      "Count 425 : new york times http://www.nytimes.com\n",
      "Count 192 : new york lottery http://www.nylottery.org\n",
      "Count 122 : new york alarm installer jobs http://websearch.nytimes.com\n",
      "Count 118 : new york university http://www.nyu.edu\n",
      "Count 96 : new york city http://www.nyc.gov\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: new york\n",
      "Results with spellchecker:\n",
      "Count 425 : new york times http://www.nytimes.com\n",
      "Count 192 : new york lottery http://www.nylottery.org\n",
      "Count 122 : new york alarm installer jobs http://websearch.nytimes.com\n",
      "Count 118 : new york university http://www.nyu.edu\n",
      "Count 96 : new york city http://www.nyc.gov\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: googol\n",
      "Results:\n",
      "Count 9 : googole http://www.googole.com\n",
      "Count 8 : googol http://en.wikipedia.org\n",
      "Count 6 : googol . com. http://mathworld.wolfram.com\n",
      "Count 1 : googolle \n",
      "Count 1 : googol.cokm \n",
      "\n",
      "\n",
      "Query fixed with spellchecker: googol\n",
      "Results with spellchecker:\n",
      "Count 9 : googole http://www.googole.com\n",
      "Count 8 : googol http://en.wikipedia.org\n",
      "Count 6 : googol . com. http://mathworld.wolfram.com\n",
      "Count 1 : googolle \n",
      "Count 1 : googol.cokm \n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: enouhg maney\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: enough money\n",
      "Results with spellchecker:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: USA sta\n",
      "Results:\n",
      "Count 1 : usa state map \n",
      "\n",
      "\n",
      "Query fixed with spellchecker: usa sta\n",
      "Results with spellchecker:\n",
      "Count 1 : usa state map \n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: Barbara \n",
      "Results:\n",
      "Count 23 : barbara ann priddy teacher oklahoma city oklahoma \n",
      "Count 21 : barbara eden http://www.imdb.com\n",
      "Count 14 : barbara a priddy oklahoma city oklahoma http://www.oklahomahistory.net\n",
      "Count 14 : barbara franzoso http://www.seacoastonline.com\n",
      "Count 13 : barbara ann priddy psychiatric history \n",
      "\n",
      "\n",
      "Query fixed with spellchecker: barbara\n",
      "Results with spellchecker:\n",
      "Count 23 : barbara ann priddy teacher oklahoma city oklahoma \n",
      "Count 21 : barbara eden http://www.imdb.com\n",
      "Count 14 : barbara a priddy oklahoma city oklahoma http://www.oklahomahistory.net\n",
      "Count 14 : barbara franzoso http://www.seacoastonline.com\n",
      "Count 13 : barbara ann priddy psychiatric history \n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: breatany\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: brittany\n",
      "Results with spellchecker:\n",
      "Count 45 : brittany murphy http://www.imdb.com\n",
      "Count 22 : brittany spears http://www.britneyspears.com\n",
      "Count 17 : brittany wells nude http://www.celebrityscandal.com\n",
      "Count 13 : brittany o'neil http://www.pinkpornstars.com\n",
      "Count 11 : brittanys http://www.americanbrittanyrescue.org\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Query: soem brikc\n",
      "Results:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "Query fixed with spellchecker: seem brick\n",
      "Results with spellchecker:\n",
      "Sorry, nothing to suggest!\n",
      "\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "inp_queries = [\"infa\", \"cliar hestory\", \"the best \", \"infarmation retrieval\", \"sherlack holm\", \"carnegie mell\", \n",
    "               \"babies r\", \"new york\", \"googol\", \"enouhg maney\", \"USA sta\", \"Barbara \", \"breatany\", \"soem brikc\"]\n",
    "\n",
    "for query in inp_queries:\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Results:\")\n",
    "    complete_user_query(query, aol_trie)\n",
    "    \n",
    "    fixed_query = process_query_with_spellchecker(query)\n",
    "    print(\"Query fixed with spellchecker:\", fixed_query)\n",
    "    print(\"Results with spellchecker:\")\n",
    "    complete_user_query(fixed_query, aol_trie)\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as you can see the spellchecker works well, and sometimes corrects the queries. For better quality of correction requires more clear data, since current data is fully based on users' queries (which can contain mistakes and noise), sometimes corrections can be wrong (or at least not clear)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Suggest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
